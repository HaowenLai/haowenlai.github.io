<!DOCTYPE html>
<html class="mozwebext" lang="en">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
		<meta http-equiv="Content-Script-Type" content="text/javascript">
		<meta http-equiv="Content-Style-Type" content="text/css">
		
		<title>Haowen Lai</title>
		<link rel="shortcut icon" href="images/favicon.png">
		<link rel="stylesheet" type="text/css" href="css/css.css">
		<link rel="stylesheet" type="text/css" href="css/style.css">
		<script src="css/hidebib.js" type="text/javascript"></script>
		<!--[if !IE]>-->
		<link rel="stylesheet" type="text/css" media="only screen and (max-device-width: 480px)" href="css/iphone.css" >
		<link rel="stylesheet" type="text/css" href="css/css_002.css" >
		<meta name="viewport" content="width=device-width; initial-scale=1.0; maximum-scale=1.0; user-scalable=0;">
	</head>
	
<body>
<div id="wrap">
	<div id="photo"><img src="images/self.png" alt="self"></div>
	<div id="profile" valign="top">
		<p class="bigskip"></p>
		<h1>Haowen Lai</h1>
		<p class="bigskip"></p>
		<p>Ph.D. Student</p>
		<p><a href="https://www.cis.upenn.edu/">Department of Computer and Information Science</a></p>
		<p><a href="https://www.upenn.edu/">University of Pennsylvania</a></p>
		<p>Philadelphia, PA 19104, USA</p>
		<p class="bigskip"></p>
		<p>hwlai@seas.upenn.edu</p>
		<div class="clear"></div>
	</div>
	<!-- end of top -->

	<div id="menu">
		<div><a href="index.html">Home</a></div>
		<div><a href="bio.html">Bio</a></div>
		<div><a href="projects.html">Projects</a></div>
		<div class="now"><a href="publications.html">Publications</a></div>
	</div>
	<!-- end of memu --> 
	
	<div id="publications" class="section">
	<h2>Publications</h2>
    <table width="100%" cellspacing="0" cellpadding="10" border="0" align="center"><tbody>
    
	<tr>
		<td width="30%" valign="top" align="center">
				<img src="images/paper_cartoradar.png" alt="paper_PanoRadar" style="border-style: none"  width="80%" >
		</td>
		<td width="70%" valign="top">
			<span class="anchor"><b>RF-Based 3D SLAM Rivaling Vision Approaches</b></span>
			<br><b><u>Haowen Lai</u></b>, Zhiwei Zheng, Mingmin Zhao
			<br>(MobiCom 2025) <span class="paper_venue">ACM International Conference on Mobile Computing and Networking (To appear)</span>
			<br>
			<div class="project_link">
				[<a href="javascript:toggleblock('paperLai2025Cartoradar_abs')">abstract</a>]
			</div><br>
			<div class="project_abs"><p id="paperLai2025Cartoradar_abs" style="display: none;">
				This paper presents CartoRadar, a novel RF-based SLAM system that delivers high-fidelity 3D mapping with 
				centimeter-level accuracy. CartoRadar builds on top of the advancements in learning-based RF imaging. 
				However, learning-based systems often exhibit variation in prediction accuracy during inference. 
				To address this challenge and enable robust RF sensing, CartoRadar introduces a novel, training-free
				uncertainty quantification method tailored to RF signals. Additionally, CartoRadar features an efficient SLAM algorithm
				that incorporates this uncertainty into the mapping process. We deploy CartoRadar on a mobile robot and conduct extensive
				evaluations across 14 floors in 5 buildings. Results show that CartoRadar achieves a trajectory error of 14.1 cm, 
				outperforming camera-based baselines by 72.1%. For mapping, CartoRadar achieves an accuracy of 7.4 cm and a completion of 8.1 cm,
				improving over vision methods by 46.2% and 67.6%, respectively. Code, datasets, and demo videos are available on our
				website.
			</p>
			</div>
		</td>
	</tr>


	<tr>
		<td width="30%" valign="top" align="center">
				<img src="images/paper_panoradar.png" alt="paper_PanoRadar" style="border-style: none"  width="80%" >
		</td>
		<td width="70%" valign="top">
			<span class="anchor"><b>Enabling Visual Recognition at Radio Frequency</b></span>
			<br><b><u>Haowen Lai</u></b>, Gaoxiang Luo, Yifei Liu, Mingmin Zhao
			<br>(MobiCom 2024) <span class="paper_venue">ACM International Conference on Mobile Computing and Networking</span>
			<br>&#127775; <b>Best Demo Award!</b>
			<br>&#127775; <b>1st Place in Student Research Competition!</b>
			<br>&#128240; <b>Media Coverage:</b> <a href="https://www.bbc.com/news/articles/cm2l1y73mz1o" target="_blank">BBC</a>, 
							<a href="https://ai.seas.upenn.edu/news/giving-robots-superhuman-vision-using-radio-signals" target="_blank">Penn Engineering</a>,
							<a href="https://mp.weixin.qq.com/s/5JxPrmARKm5gATPnBtvn6Q" target="_blank">DeepTech</a>!
			<br>
			<div class="project_link">
				[<a href="https://dl.acm.org/doi/10.1145/3636534.3649369" target="_blank">pdf</a>]
				[<a href="https://waves.seas.upenn.edu/projects/panoradar" target="_blank">project</a>]
				[<a href="https://github.com/penn-waves-lab/PanoRadar" target="_blank">code</a>]
				[<a href="https://upenn.box.com/v/panoradar-dataset" target="_blank">dataset</a>]
				[<a href="https://www.youtube.com/watch?v=dKyQ1XuPorU" target="_blank">demo</a>]
				[<a href="javascript:toggleblock('paperLai2024Panoradar_abs')">abstract</a>]
				[<a class="togglebib" href="javascript:toggleblock('paperLai2024Panoradar_bib')">bibtex</a>]
			</div><br>
			<div class="project_abs"><p id="paperLai2024Panoradar_abs" style="display: none;">
				This paper introduces PanoRadar, a novel RF imaging system that brings RF resolution close to that of LiDAR,
				while providing resilience against conditions challenging for optical signals. Our LiDAR-comparable 3D imaging
				results enable, for the first time, a variety of visual recognition tasks at radio frequency, including surface
				normal estimation, semantic segmentation, and object detection. PanoRadar utilizes a rotating single-chip mmWave
				radar, along with a combination of novel signal processing and machine learning algorithms, to create 
				high-resolution 3D images of the surroundings. Our system accurately estimates robot motion, allowing for coherent
				imaging through a dense grid of synthetic antennas. It also exploits the high azimuth resolution to enhance elevation
				resolution using learning-based methods. Furthermore, PanoRadar tackles 3D learning via 2D convolutions and addresses
				challenges due to the unique characteristics of RF signals. Our results demonstrate PanoRadar's robust performance 
				across 12 buildings. Code, datasets, and demo videos are available on our
				<a href="https://waveslab.seas.upenn.edu/projects/panoradar">website</a>.
			</p>
			<pre id="paperLai2024Panoradar_bib" xml:space="preserve" style="display: none;">@inproceedings{panoradar,
  title={Enabling Visual Recognition at Radio Frequency},
  author={Lai, Haowen and Luo, Gaoxiang and Liu, Yifei 
	and Zhao, Mingmin},
  booktitle={Proceedings of the 30th Annual International 
	Conference on Mobile Computing and Networking (MobiCom)},
  pages={388--403},
  year={2024}
}
			</pre></div>
		</td>
	</tr>


	<tr>
      	<td width="30%" valign="top" align="center">
          		<img src="images/paper_automerge.png" alt="paper_Automerge" style="border-style: none"  width="80%" >
          	</td>
		<td width="70%" valign="top">
			<span class="anchor"><a name="paperAutomerge"></a><b>AutoMerge: A Framework for Map Assembling and Smoothing in City-Scale Environments</b></span>
			<br>Peng Yin, Shiqi Zhao, <b><u>Haowen Lai</u></b>, Ruohai Ge, Ji Zhang, Howie Choset, Sebastian Scherer
			<br>(T-RO 2023) <span class="paper_venue">IEEE Transactions on Robotics</span><br>
			<div class="project_link">
				[<a href="https://ieeexplore.ieee.org/document/10203034" target="_blank">pdf</a>] 
				[<a href="https://github.com/MetaSLAM/AutoMerge_Docker" target="_blank">code</a>] 
				[<a href="javascript:toggleblock('paperYin2022Automerge_abs')">abstract</a>]
				[<a class="togglebib" href="javascript:toggleblock('paperYin2022Automerge_bib')">bibtex</a>]
			</div><br>
			<div class="project_abs"><p id="paperYin2022Automerge_abs" style="display: none;">
				In the era of advancing autonomous driving and increasing reliance on geospatial information, high-precision mapping not only 
				demands accuracy but also flexible construction. Current approaches mainly rely on expensive mapping devices, which are time 
				consuming for city-scale map construction and vulnerable to erroneous data associations without accurate GPS assistance. In this
				article, we present AutoMerge, a novel framework for merging large-scale maps that surpasses these limitations, which: 1) provides 
				robust place recognition performance despite differences in both translation and viewpoint; 2) is capable of identifying and 
				discarding incorrect loop closures caused by perceptual aliasing; and 3) effectively associates and optimizes large-scale and 
				numerous map segments in the real-world scenario. AutoMerge utilizes multiperspective fusion and adaptive loop closure detection 
				for accurate data associations, and it uses incremental merging to assemble large maps from individual trajectory segments given 
				in random order and with no initial estimations. Furthermore, AutoMerge performs pose graph optimization after assembling the 
				segments to smooth the merged map globally. We demonstrate AutoMerge on both city-scale merging (120 km) and campus-scale repeated 
				merging (4.5 km x 8). The experiments show that AutoMerge: 1) surpasses the second- and third-best methods by 0.9% and 6.5% recall 
				in segment retrieval; 2) achieves comparable 3-D mapping accuracy for 120-km large-scale map assembly; and 3) and is robust to 
				temporally spaced revisits. To our knowledge, AutoMerge is the first mapping approach to merge hundreds of kilometers of individual 
				segments without using GPS.
			</p>
			<pre id="paperYin2022Automerge_bib" xml:space="preserve" style="display: none;">@article{yin2023automerge,
  title={Automerge: A Framework for Map Assembling
  	 and Smoothing in City-Scale Environments},
  author={Yin, Peng and Zhao, Shiqi and Lai, Haowen
	 and Ge, Ruohai and Zhang, Ji and Choset, Howie
	 and Scherer, Sebastian},
  journal={IEEE Transactions on Robotics},
  volume={39},
  number={5},
  pages={3686-3704},
  year={2023}
}
			</pre></div>
		</td>
    </tr>


    <tr>
		<td width="30%" valign="top" align="center">
				<img src="images/paper_MultiplayerGuaranteed.png" alt="paper_Multiplayer_Guaranteed" style="border-style: none"  width="80%" >
			</td>
	    <td width="70%" valign="top">
		    <span class="anchor"><a name="paperTAC2021"><b>Homicidal Chauffeur Reach-Avoid Games via Guaranteed Winning Strategies</b></a></span>
		    <br>Rui Yan, Ruiliang Deng, <b><u>Haowen Lai</u></b>, Weixian Zhang, Zongying Shi, Yisheng Zhong
		    <br>(TAC 2023) <span class="paper_venue">IEEE Transactions on Automatic Control</span><br>
		    <div class="project_link" id="paperMultiplayerGuaranteed">
		 	    [<a href="https://ieeexplore.ieee.org/document/10305291" target="_blank">pdf</a>] 
		 	    [<a href="javascript:toggleblock('paperMultiplayerGuaranteed_abs')">abstract</a>]
		 	    [<a class="togglebib" href="javascript:toggleblock('paperMultiplayerGuaranteed_bib')">bibtex</a>]
		    </div><br>
		    <div class="project_abs"><p id="paperMultiplayerGuaranteed_abs" style="display: none;">
		        This article studies a planar Homicidal Chauffeur reach-avoid differential game, where the pursuer is a Dubins car and the evader 
		        has simple motion. The pursuer aims to protect a goal region from the evader. The game is solved in an analytical approach instead
		        of solving Hamilton-Jacobi-Isaacs equations numerically. First, an evasion region is introduced, based on which a pursuit strategy
		        guaranteeing the winning of a simple-motion pursuer under specific conditions is proposed. Motivated by the simple-motion pursuer,
		        a strategy for a Dubins-car pursuer is proposed when the pursuer-evader configuration satisfies separation condition (SC) and 
		        interception orientation (IO) . The necessary and sufficient condition on capture radius, minimum turning radius, and speed ratio
		        to guarantee the pursuit winning is derived. When the IO is deviated (Non-IO), a heading adjustment pursuit strategy is proposed, 
		        and the condition to achieve IO within a finite time is given. Based on it, a two-step pursuit strategy is proposed for the SC and
		        Non-IO case. A nonconvex optimization problem is introduced to give a condition guaranteeing the winning of the pursuer. A polynomial
		        equation gives a lower bound of the nonconvex problem, providing a sufficient and efficient pursuit winning condition. Finally, we 
		        extend to multiplayer games by collecting pairwise outcomes for pursuer-evader matchings. Simulations are provided to illustrate 
		        the theoretical results.</p>
		    <pre id="paperMultiplayerGuaranteed_bib" xml:space="preserve" style="display: none;">@article{yan2023homicidal,
  title={Homicidal Chauffeur Reach-Avoid Games via
     Guaranteed Winning Strategies},
  author={Yan, Rui and Deng, Ruiliang and Lai, Haowen and
     Zhang, Weixian and Shi, Zongying and Zhong, Yisheng},
  journal={IEEE Transactions on Automatic Control},
  volume={69},
  number={4},
  pages={2367-2382},
  year={2023}
}
		    </pre></div>
	    </td>
    </tr>


	<tr>
      	<td width="30%" valign="top" align="center">
          		<img src="images/paper_lai2021adafusion.png" alt="paper_AdaFusion" style="border-style: none"  width="80%" >
          	</td>
		<td width="70%" valign="top">
			<span class="anchor"><b>AdaFusion: Visual-LiDAR Fusion with Adaptive Weights for Place Recognition</b></span>
			<br><b><u>Haowen Lai</u></b>,  Peng Yin, Sebastian Scherer
			<br>(RA-L 2022) <span class="paper_venue">IEEE Robotics and Automation Letters</span><br>
			<div class="project_link">
				[<a href="https://ieeexplore.ieee.org/abstract/document/9905898" target="_blank">pdf</a>] 
				[<a href="https://github.com/MetaSLAM/AdaFusion" target="_blank">code</a>] 
				[<a href="javascript:toggleblock('paperLai2021adafusion_abs')">abstract</a>]
				[<a class="togglebib" href="javascript:toggleblock('paperLai2021adafusion_bib')">bibtex</a>]
			</div><br>
			<div class="project_abs"><p id="paperLai2021adafusion_abs" style="display: none;">
				Recent years have witnessed the increasing application of place recognition in various environments, 
				such as city roads, large buildings, and a mix of indoor and outdoor places. This task, however, still remains 
				challenging due to the limitations of different sensors and the changing appearance of environments. 
				Current works only consider the use of individual sensors, or simply combine different sensors, ignoring the 
				fact that the importance of different sensors varies as the environment changes. In this paper, an 
				adaptive weighting visual-LiDAR fusion method, named AdaFusion, is proposed to learn the weights for 
				both images and point cloud features. Features of these two modalities are thus contributed differently 
				according to the current environmental situation. The learning of weights is achieved by the attention branch 
				of the network, which is then fused with the multi-modality feature extraction branch. Furthermore, 
				to better utilize the potential relationship between images and point clouds, we design a twostage fusion approach 
				to combine the 2D and 3D attention. Our work is tested on two public datasets, and experiments show that 
				the adaptive weights help improve recognition accuracy and system robustness to varying environments. 
			</p>
			<pre id="paperLai2021adafusion_bib" xml:space="preserve" style="display: none;">@article{lai2022adafusion,
  title={Adafusion: Visual-lidar Fusion with Adaptive
	 Weights for Place Recognition},
  author={Lai, Haowen and Yin, Peng and Scherer, Sebastian},
  journal={IEEE Robotics and Automation Letters},
  volume={7},
  number={4},
  pages={12038--12045},
  year={2022},
  publisher={IEEE}
}
			</pre></div>
		</td>
    </tr>

	<tr>
		<td width="30%" valign="top" align="center">
				<img src="images/paper_ccc2022.png" alt="paper_CCC2022" style="border-style: none"  width="80%" >
			</td>
		<td width="70%" valign="top">
			<span class="anchor"><b>Global Registration of Point Cloud Maps with Low-overlap Regions</b></span>
			<br>Wenhao Liang, <b><u>Haowen Lai</u></b>, Zongying Shi, Yisheng Zhong
			<br>(CCC 2022) <span class="paper_venue">IEEE Chinese Control Conference</span><br>
			<div class="project_link">
				[<a href="https://ieeexplore.ieee.org/abstract/document/9902253" target="_blank">pdf</a>] 
				[<a href="javascript:toggleblock('paperLiangCCC2022_abs')">abstract</a>]
				[<a class="togglebib" href="javascript:toggleblock('paperLiangCCC2022_bib')">bibtex</a>]
		  	</div><br>
		  	<div class="project_abs"><p id="paperLiangCCC2022_abs" style="display: none;">
				Merging multiple maps is necessary when the task of mapping a large area is divided and assigned to 
				different robots. Unlike scanned or reconstructed models, point cloud maps built by SLAM are usually
				sparser and contain much noise, making current global registration methods failed. In this paper, we 
				focus on the global registration of point cloud maps which have low-overlap regions and no prior 
				relative transformation between each other, so that maps can still be merged in GPS-denied environment. 
				Our method adopts a pipeline of feature matching, where key points are first selected evenly within voxel 
				grids and then used for getting feature descriptors. After matching for correspondences, a RANSAC based 
				registration gives the rough transformation between maps, which can further be refined by ICP. To improve
				the accuracy of correspondences, we specifically introduce a keypoint clustering and classification method.
				Except for 3D point cloud maps as inputs, no other information is needed. Experiments on the campus show 
				that our approach successfully deals with large area with similar structures.
		  	</p>
		  	<pre id="paperLiangCCC2022_bib" xml:space="preserve" style="display: none;">@inproceedings{liang2022global,
  title={Global Registration of Point Cloud Maps with 
	 Low-overlap Regions},
  author={Liang, Wenhao and Lai, Haowen and Shi, Zongying 
	 and Zhong, Yisheng},
  booktitle={2022 41st Chinese Control Conference (CCC)},
  pages={3743--3748},
  year={2022},
  organization={IEEE}
}
			</pre></div>
		</td>
	</tr>


	<tr>
      	<td width="30%" valign="top" align="center">
          		<img src="images/paper_ReachAvoid.png" alt="paper_Reach_Avoid" style="border-style: none"  width="80%" >
          	</td>
		<td width="70%" valign="top">
			<span class="anchor"><a name="paperCDC2021"><b>Reach-Avoid Differential Games via Finite-Time Heading Tracking</b></a></span>
			<br><b><u>Haowen Lai</u></b>, Rui Yan, Weixian Zhang, Zongying Shi, Yisheng Zhong
			<br>(CDC 2021) <span class="paper_venue">IEEE Conference on Decision and Control</span><br>
			<div class="project_link" id="paperReachAvoid">
				[<a href="https://ieeexplore.ieee.org/document/9683266" target="_blank">pdf</a>]
				[<a href="javascript:toggleblock('paperReachAvoid_abs')">abstract</a>]
				[<a class="togglebib" href="javascript:toggleblock('paperReachAvoid_bib')">bibtex</a>]
			</div><br>
			<div class="project_abs"><p id="paperReachAvoid_abs" style="display: none;">
				This paper considers a one-defender-one-attacker reach-avoid differential game (DG) in the plane which is split by a 
				straight line into a goal region and a play region. The attacker aims at entering the goal region from the play region 
				without being captured, while the defender tries to capture the attacker in the play region. We focus on the defense 
				problem where the defender is a Dubins car and the attacker is a simple-motion model. First, a controller is proposed 
				for the defender to track a reference heading which is derived from an evasion space (ES)-based defense strategy. 
				Then,  an upper bound for the time derivative of the reference heading is computed. Based on it, we show that the 
				defender can succeed to track the reference heading within a finite time. Finally,  both simulation and experiment 
				examples are provided, where a vision-based re-localization method is used for the experiment to deal with the 
				coordinate inconsistency problem. 
			</p>
			<pre id="paperReachAvoid_bib" xml:space="preserve" style="display: none;">@inproceedings{lai2021ReachAvoid,
  author={Lai, Haowen and Yan, Rui and Zhang, Weixian and 
          Shi, Zongying and Zhong, Yisheng},
  booktitle={2021 60th IEEE Conference on Decision and
             Control (CDC)}, 
  title={Reach-Avoid Differential Games via Finite-Time
         Heading Tracking}, 
  year={2021},
  pages={1656-1662},
  doi={10.1109/CDC45484.2021.9683266}
}
			</pre></div>
		</td>
	</tr>
      
    <tr>
      	<td width="30%" valign="top" align="center">
          		<img src="images/paper_LidarPerception.png" alt="paper_Lidar_Perception" style="border-style: none"  width="90%" >
          	</td>
		<td width="70%" valign="top">
			<span class="anchor"><a name="paperCCC2021"><b>LiDAR-Inertial based Localization and Perception for Indoor Pursuit-Evasion Differential Games</b></a></span>
			<br><b><u>Haowen Lai</u></b>, Wenhao Liang, Rui Yan, Zongying Shi, Yisheng Zhong
			<br>(CCC 2021) <span class="paper_venue">IEEE Chinese Control Conference</span><br>
			<div class="project_link" id="paperLidarPerception">
				[<a href="https://ieeexplore.ieee.org/document/9549330" target="_blank">pdf</a>] 
				[<a href="javascript:toggleblock('paperLidarPerception_abs')">abstract</a>] 
				[<a class="togglebib" href="javascript:toggleblock('paperLidarPerception_bib')">bibtex</a>]
			</div><br>
			<div class="project_abs"><p id="paperLidarPerception_abs" style="display: none;">
				Pursuit-evasion (PE) differential games are widely studied due to their enormous application prospects in robotics. 
				Most of current works, however, focus on the theory and simulation, while even for some experiments the global 
				information is directly acquired by external devices or just by sharing, which is far from the real scenarios. Motivated 
				by this limitation, we propose a LiDAR-inertial based localization and perception method to estimate robot states 
				such as position, pose and velocity required by high-level strategies. The LiDAR-inertial odometry (LIO) that utilizes 
				data from 3D LiDAR and IMU provides self localization in an unknown environment. To locate other robots, a curve 
				fitting based algorithm for 3D LiDAR point clouds is proposed, after which a sliding window average method is 
				adopted to filter the noise in the perception results. Except for 3D LiDAR and IMU, no other sensors or communication 
				is needed. Experiments are presented to illustrate the results.
			</p>
			<pre id="paperLidarPerception_bib" xml:space="preserve" style="display: none;">@inproceedings{lai2021LiDAR,
  author={Lai, Haowen and Liang, Wenhao and Yan, Rui and 
          Shi, Zongying and Zhong, Yisheng},
  booktitle={2021 IEEE 40th Chinese Control Conference (CCC)}, 
  title={LiDAR-Inertial based Localization and Perception for 
         Indoor Pursuit-Evasion Differential Games}, 
  year={2021},
  pages={7468-7473},
  doi={10.23919/CCC52363.2021.9549330}
}
			</pre></div>
		</td>
	</tr>
      
    <tr>
      	<td width="30%" valign="top" align="center">
          		<img src="images/paper_meterReader.png" alt="paper_meter_reader" style="border-style: none"  width="90%">
          	</td>
		<td width="70%" valign="top">
			<span class="anchor"><a name="paper2019"><b>A Novel Scale Recognition Method for Pointer Meters Adapted to Different Types and Shapes</b></a></span>
			<br><b><u>Haowen Lai</u></b>, Qi Kang, Le Pan, Can Cui
			<br>(CASE 2019) <span class="paper_venue">IEEE International Conference on Automation Science and Engineering</span><br>
			<div class="project_link" id="paperMeterReader">
				[<a href="https://ieeexplore.ieee.org/document/8843107" target="_blank">pdf</a>] 
				[<a href="javascript:toggleblock('paperMeterReader_abs')">abstract</a>] 
				[<a class="togglebib" href="javascript:toggleblock('paperMeterReader_bib')">bibtex</a>] 
				[<a href="docs/Lai_CASE19_slides.pdf">slides</a>]
			</div><br>
			<div class="project_abs"><p id="paperMeterReader_abs" style="display: none;">
				Nowadays plenty of pointer meters are used in the field of chemical industry and electrical power system. To avoid 
				reading their indication manually, many algorithms based on computer vision have been proposed to read pointer meters 
				automatically. These methods, however, are limited to meters whose scales are uniform, and their accuracy is vulnerable to 
				the error in the recognition of a meter's center. In this paper, a novel automatic reading algorithm of pointer meters based on 
				scale seeking is proposed to overcome the weaknesses of the existing methods. Differing from the popular angle-based 
				methods, we obtain the indication of the meter by comparing the distances between the peak of pointer and its nearest scales. The 
				position and values of all scales can be automatically acquired and inferred by using our scale seeking and value inference 
				algorithms, which is independent of any prior information in a database. Experiments prove that the algorithm can be applied 
				to both meters with uniform or non-uniform scales effectively.
			</p>
			<pre id="paperMeterReader_bib" xml:space="preserve" style="display: none;">@inproceedings{lai2019novel,
  author = {Lai, Haowen and Kang, Qi and Pan, Le and Cui, Can},
  booktitle = {2019 IEEE 15th International Conference on 
               Automation Science and Engineering (CASE)}, 
  title = {A Novel Scale Recognition Method for Pointer 
           Meters Adapted to Different Types and Shapes}, 
  year = {2019}, 
  pages={374-379}, 
  organization={IEEE}, 
  doi={10.1109/COASE.2019.8843107}
}
			</pre></div>
		</td>
	</tr>
      
      
	</tbody></table>
	</div>  
	<!-- end div of publication --> 
	
	
	<div id="patents" class="section">
		<h2>Patents</h2><ol>
		<li>
			<b>Methods, Systems, and Computer Readable Media for Providing 3D Imaging Using Radio Frequencies</b>
			<br>Mingmin Zhao, Gaoxiang Luo, Yifei Liu, <u><b>Haowen Lai</u></b>
			<br><span class="paper_venue">US Patent Application 63/626,860, filed Jan. 2024. Patent Pending.</span>
		</li>
		<li>
			<b>Registration Method based on CNN Point Cloud Object Detection</b>
			<br>Bo Wen, Jian Zhang, Shuang Liang, Tianyi Lu, Qi Xiong, Xiaoxu Jiang, <u><b>Haowen Lai</u></b>
			<br><span class="paper_venue">China Patent CN112700479B, issued Feb. 2024.</span>
		</li>
		<li>
			<span class="anchor"><a name="patent2021"><b>A Map Construction Method and a LiDAR-inertial Odometry</b></a></span>
			<br><u><b>Haowen Lai</u></b>, Xiaoxu Jiang
			<br><span class="paper_venue">China Patent CN113358112B, issued Jan. 2023.</span>
		</li>
		<li>
			<b>Method and System for Localization based on Sensor Fusion</b>
			<br>Xiaoxu Jiang, Qi Xiong, Shuang Liang, Jian Zhang, <u><b>Haowen Lai</u></b>, Bo Wen
			<br><span class="paper_venue">China Patent CN113375666B, issued Dec. 2022.</span>
		</li>
		<li>
			<b>Method and System for Camera Calibration based on Deep Learning</b>
			<br><u><b>Haowen Lai</u></b>, et al.
			<br><span class="paper_venue">China Patent CN109493389B, issued Nov. 2021.</span>
		</li>
		<li>
			<span class="anchor"><a name="patent2018"><b>Method and System for Robot Arm Controlling based on Deep Learning</b></a></span>
			<br><u><b>Haowen Lai</u></b>, et al.
			<br><span class="paper_venue">China Patent CN109352649B, issued Jul. 2021.</span>
		</li>
		<li>
			<span class="anchor"><a name="patent2019"><b>Automatic Reading Method for Pointer Meters based on Scale Seeking</b></a></span>
			<br>Qi Kang, <u><b>Haowen Lai</u></b>
			<br><span class="paper_venue">China Patent CN109993166B, issued Oct. 2020.</span>
		</li>
	</ol></div>
	<!-- end of memu -->
	
	
	
</div>  <!-- end div wrap   -->


</body></html>